{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGnlF+Pe3cKTtEiiAu42Hz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikhildhavale/pythonLearning/blob/main/decisiontreeclassificationandregression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpSsyCCNKWko"
      },
      "outputs": [],
      "source": [
        "# Decision Tree Classification (Breast Cancer) and Regression (Diabetes)\n",
        "# Run in Google Colab / Jupyter. Requires scikit-learn, matplotlib, pandas, numpy.\n",
        "\n",
        "# 1. IMPORTS\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer, load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree, export_text\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
        "    mean_absolute_error, mean_squared_error, r2_score\n",
        ")\n",
        "\n",
        "# For nicer plots\n",
        "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# PART A — Classification Demo\n",
        "# -----------------------------\n",
        "print(\"\\n--- Decision Tree Classifier on Breast Cancer dataset ---\\n\")\n",
        "\n",
        "# 2. LOAD DATA\n",
        "bc = load_breast_cancer()\n",
        "X_bc, y_bc = bc.data, bc.target\n",
        "print(\"Breast cancer features shape:\", X_bc.shape)\n",
        "print(\"Target names:\", bc.target_names)\n",
        "\n",
        "# Optional DataFrame view\n",
        "df_bc = pd.DataFrame(X_bc, columns=bc.feature_names)\n",
        "df_bc[\"target\"] = y_bc\n",
        "print(\"\\nClass distribution (0=malignant, 1=benign):\")\n",
        "print(df_bc[\"target\"].value_counts())\n",
        "\n",
        "# 3. TRAIN-TEST SPLIT\n",
        "Xb_train, Xb_test, yb_train, yb_test = train_test_split(\n",
        "    X_bc, y_bc, test_size=0.2, random_state=42, stratify=y_bc\n",
        ")\n",
        "print(\"\\nShapes after split:\", Xb_train.shape, Xb_test.shape)\n",
        "\n",
        "# 4. TRAIN DecisionTreeClassifier\n",
        "# Choose reasonable max_depth to avoid overfitting in the demo (you can tune this)\n",
        "dt_clf = DecisionTreeClassifier(random_state=42, max_depth=10, min_samples_leaf=5)\n",
        "dt_clf.fit(Xb_train, yb_train)\n",
        "print(\"Trained DecisionTreeClassifier.\")\n",
        "\n",
        "# 5. PREDICTIONS & EVAL\n",
        "y_train_pred = dt_clf.predict(Xb_train)\n",
        "y_test_pred  = dt_clf.predict(Xb_test)\n",
        "\n",
        "train_acc = accuracy_score(yb_train, y_train_pred)\n",
        "test_acc  = accuracy_score(yb_test,  y_test_pred)\n",
        "print(f\"\\nAccuracy -> Train: {train_acc:.4f}  Test: {test_acc:.4f}\")\n",
        "\n",
        "print(\"\\nClassification report (Test):\")\n",
        "print(classification_report(yb_test, y_test_pred, target_names=bc.target_names))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(yb_test, y_test_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=bc.target_names)\n",
        "fig, ax = plt.subplots(figsize=(5,4))\n",
        "disp.plot(ax=ax, cmap=\"Blues\", values_format='d')\n",
        "plt.title(\"Decision Tree — Confusion Matrix (Test)\")\n",
        "plt.show()\n",
        "\n",
        "# 6. FEATURE IMPORTANCE (top 10)\n",
        "importances = dt_clf.feature_importances_\n",
        "feat_df = pd.DataFrame({\n",
        "    \"feature\": bc.feature_names,\n",
        "    \"importance\": importances\n",
        "}).sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\nTop features by importance:\")\n",
        "display(feat_df.head(10))\n",
        "\n",
        "# Plot feature importances (top 10)\n",
        "topk = 10\n",
        "ax = feat_df.head(topk).plot.barh(x=\"feature\", y=\"importance\", legend=False)\n",
        "ax.invert_yaxis()\n",
        "plt.title(\"Top 10 Feature Importances (Decision Tree Classifier)\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.show()\n",
        "\n",
        "# 7. SMALL TREE PLOT (limited depth to keep plots readable)\n",
        "fig, ax = plt.subplots(figsize=(16,6))\n",
        "plot_tree(dt_clf, feature_names=bc.feature_names, class_names=bc.target_names, filled=True, max_depth=5, ax=ax)\n",
        "plt.title(\"Decision Tree (first 5 levels shown)\")\n",
        "plt.show()\n",
        "\n",
        "# Optional: textual representation of rules (small)\n",
        "tree_rules = export_text(dt_clf, feature_names=list(bc.feature_names))\n",
        "print(\"\\nExtracted rules (text) — first 400 characters:\\n\")\n",
        "print(tree_rules + (\"\\n... (truncated) ...\" if len(tree_rules) > 400 else \"\"))\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# PART B — Regression Demo\n",
        "# -----------------------------\n",
        "print(\"\\n\\n--- Decision Tree Regressor on Diabetes dataset ---\\n\")\n",
        "\n",
        "# 1) LOAD DATA\n",
        "db = load_diabetes()\n",
        "X_db, y_db = db.data, db.target.astype(float)\n",
        "print(\"Diabetes features shape:\", X_db.shape)\n",
        "print(\"Feature names:\", list(db.feature_names))\n",
        "\n",
        "# Optional DataFrame\n",
        "df_db = pd.DataFrame(X_db, columns=db.feature_names)\n",
        "df_db[\"target\"] = y_db\n",
        "print(\"\\nFirst five rows (diabetes):\")\n",
        "display(df_db.head())\n",
        "\n",
        "# 2) TRAIN-TEST SPLIT\n",
        "Xr_train, Xr_test, yr_train, yr_test = train_test_split(X_db, y_db, test_size=0.2, random_state=42)\n",
        "print(\"\\nShapes after split:\", Xr_train.shape, Xr_test.shape)\n",
        "\n",
        "# 3) TRAIN DecisionTreeRegressor\n",
        "dt_reg = DecisionTreeRegressor(random_state=42, max_depth=10, min_samples_leaf=3)\n",
        "dt_reg.fit(Xr_train, yr_train)\n",
        "print(\"Trained DecisionTreeRegressor.\")\n",
        "\n",
        "# 4) PREDICT & EVALUATE\n",
        "y_pred_train = dt_reg.predict(Xr_train)\n",
        "y_pred_test  = dt_reg.predict(Xr_test)\n",
        "\n",
        "def regression_report(y_true, y_pred, label=\"\"):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    print(f\"{label}MAE : {mae:.3f}\")\n",
        "    print(f\"{label}MSE : {mse:.3f}\")\n",
        "    print(f\"{label}RMSE: {rmse:.3f}\")\n",
        "    print(f\"{label}R^2 : {r2:.4f}\")\n",
        "\n",
        "print(\"\\nRegression performance (Train):\")\n",
        "regression_report(yr_train, y_pred_train, label=\"Train \")\n",
        "print(\"\\nRegression performance (Test):\")\n",
        "regression_report(yr_test, y_pred_test, label=\"Test  \")\n",
        "\n",
        "# 5) DIAGNOSTIC PLOTS\n",
        "# Predicted vs Actual (Test)\n",
        "plt.figure()\n",
        "plt.scatter(yr_test, y_pred_test, alpha=0.7)\n",
        "min_val = min(yr_test.min(), y_pred_test.min())\n",
        "max_val = max(yr_test.max(), y_pred_test.max())\n",
        "plt.plot([min_val, max_val], [min_val, max_val], linestyle=\"--\")\n",
        "plt.xlabel(\"Actual\")\n",
        "plt.ylabel(\"Predicted\")\n",
        "plt.title(\"Decision Tree Regressor — Predicted vs Actual (Test)\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Residuals\n",
        "residuals = yr_test - y_pred_test\n",
        "plt.figure()\n",
        "plt.scatter(y_pred_test, residuals, alpha=0.7)\n",
        "plt.axhline(0.0, linestyle=\"--\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Residual (Actual - Predicted)\")\n",
        "plt.title(\"Decision Tree Regressor — Residuals (Test)\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 6) FEATURE IMPORTANCES\n",
        "imp_reg = pd.DataFrame({\n",
        "    \"feature\": db.feature_names,\n",
        "    \"importance\": dt_reg.feature_importances_\n",
        "}).sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\nTop features by importance (regression):\")\n",
        "display(imp_reg.head(10))\n",
        "\n",
        "ax = imp_reg.head(10).plot.barh(x=\"feature\", y=\"importance\", legend=False)\n",
        "ax.invert_yaxis()\n",
        "plt.title(\"Top 10 Feature Importances (Decision Tree Regressor)\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.show()\n",
        "\n",
        "# 7) SMALL TREE PLOT (regressor)\n",
        "fig, ax = plt.subplots(figsize=(24,12))\n",
        "plot_tree(dt_reg, feature_names=db.feature_names, filled=True, max_depth=3, ax=ax)\n",
        "plt.title(\"Decision Tree Regressor (first 5 levels shown)\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nDone.\")\n"
      ]
    }
  ]
}